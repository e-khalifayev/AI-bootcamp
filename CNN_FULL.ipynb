{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "392d9fcb",
   "metadata": {},
   "source": [
    "# 1. Load dataset\n",
    "#### For this programming assignment, you are provided with a dataset of handwritten letters and expected to build a CNN model that classifies given image into one of the pre-defined 28 categories. The dataset is provided in two files: train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294819fc",
   "metadata": {},
   "source": [
    "#### You will need to read the data from data files (HandChars32_150_Train.txt and HandChars32_50_Test.txt). The columns are separated by “#” sign. See the description of the columns below:\n",
    "- PatN – index (label) of image\n",
    "- PatType – written form of the letter\n",
    "- PatProb - coefficient of correctness of writing the prototype [0, .., 10].\n",
    "- SizeH, SizeW – height and width of the image, respectively\n",
    "- Data – pixels of the grayscale image\n",
    "#### For building CNN model, you will need to use PatN and Data columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d673e015",
   "metadata": {},
   "source": [
    "#### Once you read the data into a pandas DataFrame, you will need to convert Data column entries into numpy arrays of shape (32, 32). You can do so by first converting to lists of integers and then reshaping respective numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2e89251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"HandChars32_150_Train.txt\", sep='#')\n",
    "df1 = pd.read_csv(\"HandChars32_50_Test.txt\", sep = '#')\n",
    "df1 = df1[df1['PatType'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "649d7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = []\n",
    "for entry in df['Data']:\n",
    "    l = list(entry)\n",
    "    l = np.array(l, dtype=float)\n",
    "    l = l.reshape(32, 32)\n",
    "    x_train.append(l)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "y_train = df['PatN'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c13c92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4200\n",
       "Name: PatType, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PatType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc63eed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1207\n",
       "Name: PatType, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['PatType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79dc68c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = []\n",
    "for entry in df1['Data']:\n",
    "    l = list(entry)\n",
    "    l = np.array(l, dtype=float)\n",
    "    l = l.reshape(32, 32)\n",
    "    x_test.append(l)\n",
    "x_test = np.array(x_test)\n",
    "\n",
    "y_test = df1['PatN'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50198b0",
   "metadata": {},
   "source": [
    "# 2. Visualization\n",
    "#### Visualize some sample images from both train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00461b8d",
   "metadata": {},
   "source": [
    "#### You can use plt.imshow for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd9eaa8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8f21c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(x_test[1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0af169",
   "metadata": {},
   "source": [
    "# 3. Data preparation\n",
    "#### The input to your model should have shape (4200, 32, 32, 1). If your Data column is in correct shape (4200 rows of (32, 32) numpy array), you can use `stack` and `expand_dims` functions to get the desired shape. Make sure you provide correct axis when expanding the dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a7ffe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 32, 32) (1207, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a9a9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, axis = 3)\n",
    "x_test = np.expand_dims(x_test, axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3e7e8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4200, 32, 32, 1) (1207, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a98a56",
   "metadata": {},
   "source": [
    "#### The labels are in the PatN column of the data. You will need to one-hot encode the labels. You are expected to use `to_categorical` function from tensorflow.keras.utils. You will need to provide unique labels which you can find from the PatN column. Your labels for training and test sets must be (4200, 28) and (1400, 28), respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "213f4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train, num_classes = 28)\n",
    "y_test = to_categorical(y_test, num_classes = 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b70c2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe67855",
   "metadata": {},
   "source": [
    "# 4. Modeling\n",
    "#### You are expected to build a convolutional neural network and:\n",
    "- Train it on the training data\n",
    "- Perform hyperparameter tuning if needed\n",
    "- Experiment with different designs (layers, layer units, convolutional layers, pooling layers, filters, filter sizes, padding, epochs, etc.)\n",
    "- Evaluate the model using test set\n",
    "- Achieve test accuracy of ~85%\n",
    "#### You are expected to use Tensorflow library. You may need to install it first.\n",
    "#### You will be using `Sequential` module from tensoflow.keras. For an example of `Sequential` model, see the \"Tackling Fashion MNIST With a CNN\" section of the following notebook:\n",
    "https://github.com/ageron/handson-ml2/blob/master/14_deep_computer_vision_with_cnns.ipynb\n",
    "#### You can start with a simple neural network and add convolution and pooling layers as needed.\n",
    "#### You can choose \n",
    "#### Experiment with different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f069432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f598c",
   "metadata": {},
   "source": [
    "#### Build a CNN model with the following details:\n",
    "`Convolution layer with 64 filters of size (5, 5), SAME padding and ReLU activation\n",
    "Pooling layer with size (2, 2) and strides (2, 2)\n",
    "Second convolution layer with 128 filters of size (5, 5), SAME padding and ReLU activation\n",
    "Another pooling layer with same settings as previous\n",
    "Flattening layer\n",
    "Dense layer with 1024 neurons and ReLU activation\n",
    "Second dense layer with same configuration as previous\n",
    "Dense layer with 28 neurons and softmax activation\n",
    "`\n",
    "#### Your model should have 9,674,524 parameters. You can check it by calling `summary` method on your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f116b5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 16, 16, 128)       204928    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              8389632   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 28)                28700     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,674,524\n",
      "Trainable params: 9,674,524\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(shape=(32, 32, 1)),\n",
    "    layers.Conv2D(64, kernel_size = (5, 5), padding='SAME', activation = 'relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    layers.Conv2D(128, kernel_size=(5, 5),padding='SAME', activation='relu'),\n",
    "    layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(1024, activation='relu'),\n",
    "    layers.Dense(28, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30988928",
   "metadata": {},
   "source": [
    "#### Train the model for 5-10 epochs with batch size of 32, RMSprop as optimizer, categorical crossentropy as loss, and accuracy as metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d92887f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 32\n",
    "model.compile()\n",
    "model.compile(optimizer = 'RMSprop', loss = 'categorical_crossentropy', \n",
    "               metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5946e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "132/132 [==============================] - 23s 168ms/step - loss: 1.0319 - accuracy: 0.7045\n",
      "Epoch 2/5\n",
      "132/132 [==============================] - 23s 171ms/step - loss: 0.2049 - accuracy: 0.9345\n",
      "Epoch 3/5\n",
      "132/132 [==============================] - 25s 191ms/step - loss: 0.1091 - accuracy: 0.9669\n",
      "Epoch 4/5\n",
      "132/132 [==============================] - 27s 201ms/step - loss: 0.0646 - accuracy: 0.9807\n",
      "Epoch 5/5\n",
      "132/132 [==============================] - 24s 182ms/step - loss: 0.0366 - accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2955c562970>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0b1551",
   "metadata": {},
   "source": [
    "#### Perform error analysis to find out what might boost your test accuracy. You are expected to analyze the data closely. You should achieve ~90% test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b439cf3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 24ms/step - loss: 0.6073 - accuracy: 0.9072\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d08811",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
